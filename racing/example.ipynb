{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "This Notebook was developed by [Haimin Hu](https://haiminhu.org/) for the RSS'24 paper [_Blending Data-Driven Priors in Dynamic Games_](https://kl-games.github.io).\n",
        "\n",
        "Instructions:\n",
        "* Run the cells to initiate closed-loop simulation for each method.\n",
        "* The simulation results are automatically displayed as an animation within the Notebook.\n",
        "* The reference policy uses a pre-trained neural game solver. If you want to train your own model, please refer to [Neural NOD](https://arxiv.org/pdf/2406.09810) for the training code.\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f791dda0",
      "metadata": {},
      "source": [
        "##### KLGame (overtaking ref. policy only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99d7568",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import jax\n",
        "from flax import serialization\n",
        "import imageio.v2 as imageio\n",
        "from matplotlib import cm\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.transforms import Affine2D\n",
        "from IPython.display import Image\n",
        "\n",
        "from iLQR.utils import *\n",
        "from iLQGame.utils import *\n",
        "from iLQR import Dynamics\n",
        "from iLQGame import ILQSolver, KLGameSolver, ExplicitMLP, ProductMultiPlayerDynamicalSystem\n",
        "\n",
        "# region: Problem setup\n",
        "ado_mode = \"ilq\"  # \"orig\", \"ilq\"\n",
        "with open('model/mlp_params.pkl', 'rb') as f:\n",
        "  model_params_tmp = pickle.load(f)\n",
        "\n",
        "EGO_REF_VEL_SCALE, ADO_REF_VEL_SCALE = 0.7, 0.7\n",
        "\n",
        "jax.config.update('jax_platform_name', 'cpu')\n",
        "jax.config.update('jax_enable_x64', True)\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
        "plt.rcParams['axes.titlepad'] = 40\n",
        "\n",
        "# Loads the config and track file.\n",
        "config = load_config(\"config/default.yaml\")\n",
        "config_cautious = load_config(\"config/cautious.yaml\")\n",
        "config_nn = get_nn_config(config)\n",
        "track_name = \"thunderhill_track\"\n",
        "track = load_track_variable_width(track_name)\n",
        "\n",
        "itr_receding = config.MAX_ITER_RECEDING\n",
        "\n",
        "# Ego ellipsoidal footprint\n",
        "ego_a = config.LENGTH / 2.0\n",
        "ego_b = config.WIDTH / 2.0\n",
        "ego_q = np.array([config.WHEELBASE / 2., 0])[:, np.newaxis]\n",
        "ego_Q = np.diag([ego_a * ego_a, ego_b * ego_b])\n",
        "\n",
        "# Specifies the folder to save figures.\n",
        "fig_prog_folder_zoom_in = os.path.join(config.OUT_FOLDER, \"progress_zoom_in_MLP\")\n",
        "os.makedirs(fig_prog_folder_zoom_in, exist_ok=True)\n",
        "supra = plt.imread('tracks/supra.png', format=\"png\")\n",
        "benz = plt.imread('tracks/benz.png', format=\"png\")\n",
        "\n",
        "# Creates subsystems and the joint system.\n",
        "ego_idx = 0\n",
        "ado_idx = 1\n",
        "ego_subsys = Dynamics(ego_idx, config, ref_vel_scaling=EGO_REF_VEL_SCALE)\n",
        "ado_subsys = Dynamics(ado_idx, config, ref_vel_scaling=ADO_REF_VEL_SCALE)\n",
        "jnt_sys = ProductMultiPlayerDynamicalSystem([ego_subsys, ado_subsys])\n",
        "\n",
        "# Loads the dataset.\n",
        "with open(\"dataset/dataset.pkl\", 'rb') as handle:\n",
        "  ds = pickle.load(handle)\n",
        "\n",
        "# Sets up the iLQGame solver.\n",
        "solver_klg = KLGameSolver(track, config, jnt_sys, verbose=False)\n",
        "solver = ILQSolver(track, config, jnt_sys, verbose=False)\n",
        "solver_cautious = ILQSolver(track, config_cautious, jnt_sys, verbose=False)\n",
        "solver.normalize_nn_input(ds['data'].T)\n",
        "config_eval = deepcopy(config)\n",
        "config_eval.W_BLOCK = 20.\n",
        "config_eval.W_INNER_ADO = 0.\n",
        "config_eval.W_OUTER_ADO = 0.5\n",
        "solver_ado = ILQSolver(track, config_eval, jnt_sys, verbose=False)\n",
        "solver_neutral = ILQSolver(track, deepcopy(config), jnt_sys, verbose=False)\n",
        "solver_neutral.set_neutral_weights()\n",
        "\n",
        "# Loads NN params\n",
        "solver.cost_param_model = ExplicitMLP(\n",
        "    features=config_nn.network_features, cutoff=True, config=config, is_softmax=True,\n",
        "    px_rel_min=solver._data_min[0, 0], px_rel_range=solver._data_max[0, 0] - solver._data_min[0, 0],\n",
        "    py_rel_min=solver._data_min[1, 0], py_rel_range=solver._data_max[1, 0] - solver._data_min[1, 0]\n",
        ")\n",
        "key = jax.random.PRNGKey(config_nn.random_seed)\n",
        "model_params = solver.cost_param_model.init(key, jnp.zeros((config_nn.network_dim_in,)))\n",
        "model_params = serialization.from_state_dict(model_params, model_params_tmp)\n",
        "# endregion\n",
        "\n",
        "# region: Specifies the initial state.\n",
        "pos0_ego, psi0_ego = track.interp([2280], mode='center')  # track.length = 2673.5\n",
        "pos0_ado, psi0_ado = track.interp([2325], mode='center')\n",
        "x_init = np.array([\n",
        "    pos0_ego[0], pos0_ego[1], 0., psi0_ego[0], pos0_ado[0], pos0_ado[1], 0., psi0_ado[0]\n",
        "])\n",
        "# endregion\n",
        "\n",
        "# region: Main simulation loop.\n",
        "# Initializes the simulation.\n",
        "x_cur = deepcopy(x_init)\n",
        "state_hist = np.zeros((solver.dim_x, itr_receding))\n",
        "control_hist = np.zeros((solver.dim_u_ss, itr_receding, solver.num_players))\n",
        "_identity_matrix = np.eye(config.DIM_U)\n",
        "rSigmas = np.tile(_identity_matrix[:, :, np.newaxis, np.newaxis], (1, 1, config.N, 2))\n",
        "theta_ego_hist, theta_ado_hist = [], []\n",
        "t_total = 0.\n",
        "_ot_flag = False\n",
        "dh = display(HTML('<pre>KLGame planning starts.</pre>'), display_id=True)\n",
        "\n",
        "for i in range(itr_receding):\n",
        "\n",
        "  # region: Ego Planning\n",
        "  # Updates the nominal control signal for warmstart of the next planning cycle.\n",
        "  controls_ws = np.zeros((solver.dim_u_ss, config.N, solver.num_players))\n",
        "  if i > 0:\n",
        "    controls_ws[:, :-1, :] = controls[:, 1:, :]\n",
        "\n",
        "  # Plans mode trajectories using learned game policy.\n",
        "  # -> Overtake\n",
        "  states_ov, controls_ov, _, _, _, _, _ = solver.solve_parametric(model_params, x_cur, controls_ws)\n",
        "\n",
        "  # Solves KLGame.\n",
        "  ref_mus = [controls_ov]\n",
        "  states, controls, t_process, status, thetas, mode = solver_klg.solve(\n",
        "      x_cur, controls_ws, ref_mus, [rSigmas], [config.REG_EGO, config.REG_ADO]\n",
        "  )\n",
        "  # endregion\n",
        "\n",
        "  # region: Ado Planning\n",
        "  progress = np.asarray(thetas[0, 0, :]) / track.length\n",
        "  _ot_flag = progress[ego_idx] > progress[ado_idx] + 0.001\n",
        "  if _ot_flag:\n",
        "    solver_ado = solver_neutral\n",
        "\n",
        "  if ado_mode == \"ilq\":\n",
        "    _, controls_ado, _, _, _ = solver_ado.solve(x_cur, controls_ws)\n",
        "    controls = deepcopy(controls)\n",
        "    controls[:, 0, ado_idx] = controls_ado[:, 0, ado_idx]\n",
        "  # endregion\n",
        "\n",
        "  # region: Executes the control, records states and controls, computes the progress.\n",
        "  x_cur, _ = solver.dynamics.integrate_forward(x_cur, controls[:, 0, :])\n",
        "  x_cur = np.asarray(x_cur)\n",
        "\n",
        "  state_hist[:, i] = x_cur\n",
        "  control_hist[:, i, :] = controls[:, 0, :]\n",
        "  theta_ego_hist.append(thetas[0, 0, ego_idx])\n",
        "  theta_ado_hist.append(thetas[0, 0, ado_idx])\n",
        "\n",
        "  if i > 0:  # Updates computation time: excludes JAX compilation time at the first time step.\n",
        "    t_total += t_process\n",
        "  # endregion\n",
        "\n",
        "  # region: Plots the current progress.\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  track.plot_track(N_pts=1000, plot_raceline=False)\n",
        "  plt.plot(states[0, 1:], states[1, 1:], linewidth=6, c='red', alpha=1)  # ego plan\n",
        "  # plt.plot(states[4, 1:], states[5, 1:], linewidth=2, c='b')  # ado plan\n",
        "  plt.plot(states_ov[0, 1:], states_ov[1, 1:], linewidth=3, linestyle='--', c='orange', alpha=1)\n",
        "\n",
        "  transform_data = Affine2D().rotate_deg_around(*(x_cur[0], x_cur[1]),\n",
        "                                                x_cur[3] / np.pi * 180) + plt.gca().transData\n",
        "  plt.imshow(\n",
        "      supra, transform=transform_data, interpolation='none', origin='lower',\n",
        "      extent=[x_cur[0] - 1., x_cur[0] + 4., x_cur[1] - 1.,\n",
        "              x_cur[1] + 1.], alpha=1.0, zorder=10.0, clip_on=True\n",
        "  )  # plot ego car figure\n",
        "  transform_data = Affine2D().rotate_deg_around(*(x_cur[4], x_cur[5]),\n",
        "                                                x_cur[7] / np.pi * 180) + plt.gca().transData\n",
        "  plt.imshow(\n",
        "      benz, transform=transform_data, interpolation='none', origin='lower',\n",
        "      extent=[x_cur[4] - 1.2, x_cur[4] + 4., x_cur[5] - 1.3,\n",
        "              x_cur[5] + 1.3], alpha=1.0, zorder=10.0, clip_on=True\n",
        "  )  # plot ado car figure\n",
        "  sc = plt.scatter(\n",
        "      state_hist[0, :i + 1], state_hist[1, :i + 1], s=400, c=state_hist[2, :i + 1], cmap=cm.jet,\n",
        "      vmin=0, vmax=config.V_MAX, edgecolor='none', marker='o'\n",
        "  )  # trajectory history\n",
        "  plt.axis('equal')\n",
        "  plt.xlim([states[0, 0] - 30., states[0, 0] + 30.])\n",
        "  plt.ylim([states[1, 0] - 30., states[1, 0] + 30.])\n",
        "  plt.title(\"step: \" + str(i) + \" | mode: \" + str(mode))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.savefig(os.path.join(fig_prog_folder_zoom_in, str(i) + \".png\"), dpi=50)\n",
        "  plt.rcParams.update({'font.size': 25})\n",
        "  plt.close()\n",
        "  # endregion\n",
        "\n",
        "  # region: Reports simulation status.\n",
        "  _info = [\n",
        "      'step: ', i, ' | ego prog: ', '{:04.2f}'.format(progress[ego_idx]), ' | ado prog: ',\n",
        "      '{:04.2f}'.format(progress[ado_idx]), ' | stime: ', '{:04.2f}'.format(t_process), ' | mode: ',\n",
        "      mode\n",
        "  ]\n",
        "  _info = [str(_item) for _item in _info]\n",
        "  dh.update(''.join(_info))\n",
        "  # endregion\n",
        "\n",
        "# region: Wraps up the simulation.\n",
        "plt.close('All')\n",
        "print(\"Avg. computation time is {:.3f} s per planning cycle.\".format(t_total / (itr_receding-1)))\n",
        "print(\"Completed a race on\", track_name, \"in \", round((i+1) * ego_subsys.dt, 2), 's')\n",
        "\n",
        "# Makes animations.\n",
        "gif_path_zoom_in = os.path.join(config.OUT_FOLDER, 'rollout_zoom_in_KLG.gif')\n",
        "with imageio.get_writer(gif_path_zoom_in, mode='I', loop=0) as writer_zoom_in:\n",
        "  for j in range(i):\n",
        "    filename = os.path.join(fig_prog_folder_zoom_in, str(j) + \".png\")\n",
        "    image = imageio.imread(filename)\n",
        "    writer_zoom_in.append_data(image)\n",
        "img = Image(open(gif_path_zoom_in, 'rb').read())\n",
        "display(img)\n",
        "# endregion\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940aadde",
      "metadata": {},
      "source": [
        "##### Multi-modal KLGame (overtaking and car-following)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebfd1f14",
      "metadata": {},
      "outputs": [],
      "source": [
        "# region: Main simulation loop.\n",
        "# Initializes the simulation.\n",
        "x_cur = deepcopy(x_init)\n",
        "state_hist = np.zeros((solver.dim_x, itr_receding))\n",
        "control_hist = np.zeros((solver.dim_u_ss, itr_receding, solver.num_players))\n",
        "_identity_matrix = np.eye(config.DIM_U)\n",
        "rSigmas = np.tile(_identity_matrix[:, :, np.newaxis, np.newaxis], (1, 1, config.N, 2))\n",
        "theta_ego_hist, theta_ado_hist = [], []\n",
        "t_total = 0.\n",
        "_ot_flag = False\n",
        "dh = display(HTML('<pre>KLGame planning starts.</pre>'), display_id=True)\n",
        "\n",
        "for i in range(itr_receding):\n",
        "\n",
        "  # region: Ego Planning\n",
        "  # Updates the nominal control signal for warmstart of the next planning cycle.\n",
        "  controls_ws = np.zeros((solver.dim_u_ss, config.N, solver.num_players))\n",
        "  if i > 0:\n",
        "    controls_ws[:, :-1, :] = controls[:, 1:, :]\n",
        "\n",
        "  # Plans modal trajectories using reference game policies.\n",
        "  # -> Time-optimal\n",
        "  if not _ot_flag:\n",
        "    states_to, controls_to, _, _, _ = solver_cautious.solve(x_cur, controls_ws)\n",
        "  else:\n",
        "    states_to, controls_to, _, _, _ = solver_neutral.solve(x_cur, controls_ws)\n",
        "  # -> Overtake\n",
        "  states_ov, controls_ov, _, _, _, _, _ = solver.solve_parametric(model_params, x_cur, controls_ws)\n",
        "\n",
        "  # Solves KLGame.\n",
        "  ref_mus = [controls_ov, controls_to]\n",
        "  states, controls, t_process, status, thetas, mode = solver_klg.solve(\n",
        "      x_cur, controls_ws, ref_mus, [rSigmas, rSigmas], [config.REG_EGO, config.REG_ADO]\n",
        "  )\n",
        "  # endregion\n",
        "\n",
        "  # region: Ado Planning\n",
        "  progress = np.asarray(thetas[0, 0, :]) / track.length\n",
        "  _ot_flag = progress[ego_idx] > progress[ado_idx] + 0.001\n",
        "  if _ot_flag:\n",
        "    solver_ado = solver_neutral\n",
        "\n",
        "  if ado_mode == \"ilq\":\n",
        "    _, controls_ado, _, _, _ = solver_ado.solve(x_cur, controls_ws)\n",
        "    controls = deepcopy(controls)\n",
        "    controls[:, 0, ado_idx] = controls_ado[:, 0, ado_idx]\n",
        "  # endregion\n",
        "\n",
        "  # region: Executes the control, records states and controls, computes the progress.\n",
        "  x_cur, _ = solver.dynamics.integrate_forward(x_cur, controls[:, 0, :])\n",
        "  x_cur = np.asarray(x_cur)\n",
        "\n",
        "  state_hist[:, i] = x_cur\n",
        "  control_hist[:, i, :] = controls[:, 0, :]\n",
        "  theta_ego_hist.append(thetas[0, 0, ego_idx])\n",
        "  theta_ado_hist.append(thetas[0, 0, ado_idx])\n",
        "\n",
        "  if i > 0:  # Updates computation time: excludes JAX compilation time at the first time step.\n",
        "    t_total += t_process\n",
        "  # endregion\n",
        "\n",
        "  # region: Plots the current progress.\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  track.plot_track(N_pts=1000, plot_raceline=False)\n",
        "  plt.plot(states[0, 1:], states[1, 1:], linewidth=6, c='red', alpha=1)  # ego plan\n",
        "  # plt.plot(states[4, 1:], states[5, 1:], linewidth=2, c='b')  # ado plan\n",
        "  plt.plot(states_ov[0, 1:], states_ov[1, 1:], linewidth=3, linestyle='--', c='orange', alpha=1)\n",
        "  plt.plot(states_to[0, 1:], states_to[1, 1:], linewidth=3, linestyle='--', c='blue', alpha=1)\n",
        "\n",
        "  transform_data = Affine2D().rotate_deg_around(*(x_cur[0], x_cur[1]),\n",
        "                                                x_cur[3] / np.pi * 180) + plt.gca().transData\n",
        "  plt.imshow(\n",
        "      supra, transform=transform_data, interpolation='none', origin='lower',\n",
        "      extent=[x_cur[0] - 1., x_cur[0] + 4., x_cur[1] - 1.,\n",
        "              x_cur[1] + 1.], alpha=1.0, zorder=10.0, clip_on=True\n",
        "  )  # plot ego car figure\n",
        "  transform_data = Affine2D().rotate_deg_around(*(x_cur[4], x_cur[5]),\n",
        "                                                x_cur[7] / np.pi * 180) + plt.gca().transData\n",
        "  plt.imshow(\n",
        "      benz, transform=transform_data, interpolation='none', origin='lower',\n",
        "      extent=[x_cur[4] - 1.2, x_cur[4] + 4., x_cur[5] - 1.3,\n",
        "              x_cur[5] + 1.3], alpha=1.0, zorder=10.0, clip_on=True\n",
        "  )  # plot ado car figure\n",
        "  sc = plt.scatter(\n",
        "      state_hist[0, :i + 1], state_hist[1, :i + 1], s=400, c=state_hist[2, :i + 1], cmap=cm.jet,\n",
        "      vmin=0, vmax=config.V_MAX, edgecolor='none', marker='o'\n",
        "  )  # trajectory history\n",
        "  plt.axis('equal')\n",
        "  plt.xlim([states[0, 0] - 30., states[0, 0] + 30.])\n",
        "  plt.ylim([states[1, 0] - 30., states[1, 0] + 30.])\n",
        "  plt.title(\"step: \" + str(i) + \" | mode: \" + str(mode))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.savefig(os.path.join(fig_prog_folder_zoom_in, str(i) + \".png\"), dpi=50)\n",
        "  plt.rcParams.update({'font.size': 25})\n",
        "  plt.close()\n",
        "  # endregion\n",
        "\n",
        "  # region: Reports simulation status.\n",
        "  _info = [\n",
        "      'step: ', i, ' | ego prog: ', '{:04.2f}'.format(progress[ego_idx]), ' | ado prog: ',\n",
        "      '{:04.2f}'.format(progress[ado_idx]), ' | stime: ', '{:04.2f}'.format(t_process), ' | mode: ',\n",
        "      mode\n",
        "  ]\n",
        "  _info = [str(_item) for _item in _info]\n",
        "  dh.update(''.join(_info))\n",
        "  # endregion\n",
        "\n",
        "# region: Wraps up the simulation.\n",
        "plt.close('All')\n",
        "print(\"Avg. computation time is {:.3f} s per planning cycle.\".format(t_total / (itr_receding-1)))\n",
        "print(\"Completed a race on\", track_name, \"in \", round((i+1) * ego_subsys.dt, 2), 's')\n",
        "\n",
        "# Makes animations.\n",
        "gif_path_zoom_in = os.path.join(config.OUT_FOLDER, 'rollout_zoom_in_KLG.gif')\n",
        "with imageio.get_writer(gif_path_zoom_in, mode='I', loop=0) as writer_zoom_in:\n",
        "  for j in range(i):\n",
        "    filename = os.path.join(fig_prog_folder_zoom_in, str(j) + \".png\")\n",
        "    image = imageio.imread(filename)\n",
        "    writer_zoom_in.append_data(image)\n",
        "img = Image(open(gif_path_zoom_in, 'rb').read())\n",
        "display(img)\n",
        "# endregion\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2da4dfd",
      "metadata": {},
      "source": [
        "##### Multi-modal reference policy (baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635ff2f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# region: Main simulation loop.\n",
        "# Initializes the simulation.\n",
        "x_cur = deepcopy(x_init)\n",
        "state_hist = np.zeros((solver.dim_x, itr_receding))\n",
        "control_hist = np.zeros((solver.dim_u_ss, itr_receding, solver.num_players))\n",
        "_identity_matrix = np.eye(config.DIM_U)\n",
        "rSigmas = np.tile(_identity_matrix[:, :, np.newaxis, np.newaxis], (1, 1, config.N, 2))\n",
        "theta_ego_hist, theta_ado_hist = [], []\n",
        "t_total = 0.\n",
        "_ot_flag = False\n",
        "dh = display(HTML('<pre>KLGame planning starts.</pre>'), display_id=True)\n",
        "\n",
        "for i in range(itr_receding):\n",
        "\n",
        "  # region: Ego Planning\n",
        "  # Updates the nominal control signal for warmstart of the next planning cycle.\n",
        "  controls_ws = np.zeros((solver.dim_u_ss, config.N, solver.num_players))\n",
        "  if i > 0:\n",
        "    controls_ws[:, :-1, :] = controls[:, 1:, :]\n",
        "\n",
        "  # Plans modal trajectories using reference game policies.\n",
        "  # -> Time-optimal\n",
        "  if not _ot_flag:\n",
        "    states_to, controls_to, _, _, _ = solver_cautious.solve(x_cur, controls_ws)\n",
        "  else:\n",
        "    states_to, controls_to, _, _, _ = solver_neutral.solve(x_cur, controls_ws)\n",
        "  # -> Overtake\n",
        "  states_ov, controls_ov, _, _, _, _, _ = solver.solve_parametric(model_params, x_cur, controls_ws)\n",
        "\n",
        "  # Switches policies based on collision checking.\n",
        "  controls = controls_ov\n",
        "  mode = 'ov'\n",
        "  for k in range(solver.horizon):\n",
        "    obs_tuple_cur = get_perfect_obs_two_player(states_ov[:, k], controls_ov[:, k, :], solver)\n",
        "    if not is_safe(config, obs_tuple_cur):\n",
        "      controls = controls_to\n",
        "      mode = 'to'\n",
        "      break\n",
        "  controls = np.asarray(controls)\n",
        "  # endregion\n",
        "\n",
        "  # region: Ado Planning\n",
        "  if ado_mode == \"ilq\":\n",
        "    _, controls_ado, _, _, thetas = solver_ado.solve(x_cur, controls_ws)\n",
        "    controls = deepcopy(controls)\n",
        "    controls[:, 0, ado_idx] = controls_ado[:, 0, ado_idx]\n",
        "\n",
        "  progress = np.asarray(thetas[0, 0, :]) / track.length\n",
        "  _ot_flag = progress[ego_idx] > progress[ado_idx] + 0.001\n",
        "  if _ot_flag:\n",
        "    solver_ado = solver_neutral\n",
        "  # endregion\n",
        "\n",
        "  # region: Executes the control, records states and controls, computes the progress.\n",
        "  x_cur, _ = solver.dynamics.integrate_forward(x_cur, controls[:, 0, :])\n",
        "  x_cur = np.asarray(x_cur)\n",
        "\n",
        "  state_hist[:, i] = x_cur\n",
        "  control_hist[:, i, :] = controls[:, 0, :]\n",
        "  theta_ego_hist.append(thetas[0, 0, ego_idx])\n",
        "  theta_ado_hist.append(thetas[0, 0, ado_idx])\n",
        "  # endregion\n",
        "\n",
        "  # region: Plots the current progress.\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  track.plot_track(N_pts=1000, plot_raceline=False)\n",
        "  # plt.plot(states[0, 1:], states[1, 1:], linewidth=6, c='red', alpha=1)  # ego plan\n",
        "  # plt.plot(states[4, 1:], states[5, 1:], linewidth=2, c='b')  # ado plan\n",
        "  if mode == 'ov':\n",
        "    plt.plot(states_ov[0, 1:], states_ov[1, 1:], linewidth=3, linestyle='--', c='orange', alpha=1)\n",
        "    plt.plot(states_to[0, 1:], states_to[1, 1:], linewidth=3, linestyle='--', c='blue', alpha=0.3)\n",
        "  else:\n",
        "    plt.plot(states_ov[0, 1:], states_ov[1, 1:], linewidth=3, linestyle='--', c='orange', alpha=0.3)\n",
        "    plt.plot(states_to[0, 1:], states_to[1, 1:], linewidth=3, linestyle='--', c='blue', alpha=1)\n",
        "\n",
        "  transform_data = Affine2D().rotate_deg_around(*(x_cur[0], x_cur[1]),\n",
        "                                                x_cur[3] / np.pi * 180) + plt.gca().transData\n",
        "  plt.imshow(\n",
        "      supra, transform=transform_data, interpolation='none', origin='lower',\n",
        "      extent=[x_cur[0] - 1., x_cur[0] + 4., x_cur[1] - 1.,\n",
        "              x_cur[1] + 1.], alpha=1.0, zorder=10.0, clip_on=True\n",
        "  )  # plot ego car figure\n",
        "  transform_data = Affine2D().rotate_deg_around(*(x_cur[4], x_cur[5]),\n",
        "                                                x_cur[7] / np.pi * 180) + plt.gca().transData\n",
        "  plt.imshow(\n",
        "      benz, transform=transform_data, interpolation='none', origin='lower',\n",
        "      extent=[x_cur[4] - 1.2, x_cur[4] + 4., x_cur[5] - 1.3,\n",
        "              x_cur[5] + 1.3], alpha=1.0, zorder=10.0, clip_on=True\n",
        "  )  # plot ado car figure\n",
        "  sc = plt.scatter(\n",
        "      state_hist[0, :i + 1], state_hist[1, :i + 1], s=400, c=state_hist[2, :i + 1], cmap=cm.jet,\n",
        "      vmin=0, vmax=config.V_MAX, edgecolor='none', marker='o'\n",
        "  )  # trajectory history\n",
        "  plt.axis('equal')\n",
        "  plt.xlim([states_ov[0, 0] - 30., states_ov[0, 0] + 30.])\n",
        "  plt.ylim([states_ov[1, 0] - 30., states_ov[1, 0] + 30.])\n",
        "  plt.title(\"step: \" + str(i) + \" | mode: \" + str(mode))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.savefig(os.path.join(fig_prog_folder_zoom_in, str(i) + \".png\"), dpi=50)\n",
        "  plt.rcParams.update({'font.size': 25})\n",
        "  plt.close()\n",
        "  # endregion\n",
        "\n",
        "  # region: Reports simulation status.\n",
        "  _info = [\n",
        "      'step: ', i, ' | ego prog: ', '{:04.2f}'.format(progress[ego_idx]), ' | ado prog: ',\n",
        "      '{:04.2f}'.format(progress[ado_idx]), ' | mode: ', mode\n",
        "  ]\n",
        "  _info = [str(_item) for _item in _info]\n",
        "  dh.update(''.join(_info))\n",
        "  # endregion\n",
        "\n",
        "# region: Wraps up the simulation.\n",
        "plt.close('All')\n",
        "print(\"Avg. computation time is {:.3f} s per planning cycle.\".format(t_total / (itr_receding-1)))\n",
        "print(\"Completed a race on\", track_name, \"in \", round((i+1) * ego_subsys.dt, 2), 's')\n",
        "\n",
        "# Makes animations.\n",
        "gif_path_zoom_in = os.path.join(config.OUT_FOLDER, 'rollout_zoom_in_KLG.gif')\n",
        "with imageio.get_writer(gif_path_zoom_in, mode='I', loop=0) as writer_zoom_in:\n",
        "  for j in range(i):\n",
        "    filename = os.path.join(fig_prog_folder_zoom_in, str(j) + \".png\")\n",
        "    image = imageio.imread(filename)\n",
        "    writer_zoom_in.append_data(image)\n",
        "img = Image(open(gif_path_zoom_in, 'rb').read())\n",
        "display(img)\n",
        "# endregion\n",
        "# endregion"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
